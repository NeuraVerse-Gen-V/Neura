import torch
import torch.nn as nn
import torch.nn.functional as F


"""
______Transformer Model Components______

Positional encoding
Multi head attention
scaled dot product attention
Layer norm
Position-wise feed forward network
Encoder layer
Encoder
Decoder layer
Decoder

"""

class PositionalEncoding(nn.module):
    pass # Placeholder for positional encoding implementation

class MultiHeadAttention(nn.module):
    pass # Placeholder for multi-head attention implementation

class ScaledDotProductAttention(nn.module):
    pass # Placeholder for scaled dot product attention implementation

class LayerNorm(nn.module):
    pass # Placeholder for layer normalization implementation

class PositionwiseFeedForward(nn.module):
    pass # Placeholder for position-wise feed forward network implementation

class EncoderLayer(nn.module):
    pass # Placeholder for encoder layer implementation

class Encoder(nn.module):
    pass # Placeholder for encoder implementation

class DecoderLayer(nn.module):
    pass # Placeholder for decoder layer implementation

class Decoder(nn.module):
    pass # Placeholder for decoder implementation

class Transformer(nn.module):
    pass # Placeholder for the Transformer model implementation